{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Stacking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrej-Ilin/practice/blob/main/Stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVGEqntXHZeD"
      },
      "source": [
        "# 6.2 Стекинг"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IREftSDTHZeE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.base import clone\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J0r6DYGHZeH"
      },
      "source": [
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz', sep=',', header=None)[:10000]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7SUi2FRHZeJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "9dda3c09-dbad-4ec8-bb47-6bca41262cdb"
      },
      "source": [
        "df.head(3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1   2    3   4     5    6    7   ...  47  48  49  50  51  52  53  54\n",
              "0  2596   51   3  258   0   510  221  232  ...   0   0   0   0   0   0   0   5\n",
              "1  2590   56   2  212  -6   390  220  235  ...   0   0   0   0   0   0   0   5\n",
              "2  2804  139   9  268  65  3180  234  238  ...   0   0   0   0   0   0   0   2\n",
              "\n",
              "[3 rows x 55 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjzuwk_aHZeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8760db3d-9b42-4923-cb4d-376022e0c124"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 55)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYKjBKSsHZeO"
      },
      "source": [
        "features = list(range(0, 54))\n",
        "target = 54\n",
        "\n",
        "df = df[(df[target] == 1) | (df[target] == 2)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muwO4M4sHZeQ"
      },
      "source": [
        "cover_train, cover_test = train_test_split(df, test_size=0.5)\n",
        "\n",
        "cover_X_train, cover_y_train = cover_train[features], cover_train[target]\n",
        "cover_X_test, cover_y_test = cover_test[features], cover_test[target]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97GG-s4cHZeS"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "cover_X_train = scaler.fit_transform(cover_X_train)\n",
        "cover_X_test = scaler.transform(cover_X_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh3F1HqhrbTH"
      },
      "source": [
        "n_classes = len(np.unique(cover_y_train)) # \n",
        "X_meta_train = np.zeros((len(cover_X_train), n_classes), dtype=np.float32)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDL92rlnrzrh",
        "outputId": "2dc72868-5605-4349-e3a1-acf4d67f2ed3"
      },
      "source": [
        "X_meta_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       ...,\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRnSXWqzKh3x"
      },
      "source": [
        "Stacking — еще один способ объединить несколько алгоритмов в один, который часто используется как в решении реальных задач из промышленной сферы, так и в конкурсах на платформах вроде Kaggle.  \n",
        "Подход использует понятие _базовых классификаторов_, каждый из которых независимо обучается на некотором (возможно одном и том же) множестве признаков, а также _мета-классификатора_, использующего предсказания базовых классификаторов как признаки.\n",
        "\n",
        "Для избежания переобучения будем разбивать обучающую выборку на фолды.  \n",
        "Например, фолды при разбиении на три части:  \n",
        "``==*``  \n",
        "``=*=``  \n",
        "``*==``  \n",
        "\n",
        "Это требуется для того, чтобы получить новые признаки (ответы алгоритмов на первом уровне) на всей обучающей выборке, т.е. ответы алгоритма на тех объектах, которые не были использованы во время обучения. В примере выше мы будем использовать ответы алгоритма, полученные на объектах звездочках. _Важно_: на каждом фолде мы обучаем алгоритм заново."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcomzpKcHZeU"
      },
      "source": [
        "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n",
        "    \"\"\"\n",
        "    Computes meta-features using the classifier.\n",
        "    \n",
        "    :arg clf: scikit-learn classifier\n",
        "    :args X_train, y_train: training set\n",
        "    :arg X_test: testing set\n",
        "    :arg cv: cross-validation folding\n",
        "    \"\"\"\n",
        "    X_meta_train = np.zeros_like(y_train, dtype=np.float32)\n",
        "    for train_fold_index, predict_fold_index in cv.split(X_train):\n",
        "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
        "        y_fold_train = y_train[train_fold_index]\n",
        "        \n",
        "        folded_clf = clone(clf)\n",
        "        folded_clf.fit(X_fold_train, y_fold_train)\n",
        "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)[:, 1]\n",
        "    \n",
        "    meta_clf = clone(clf)\n",
        "    meta_clf.fit(X_train, y_train)\n",
        "    \n",
        "    X_meta_test = meta_clf.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    return X_meta_train, X_meta_test"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcKj44HrHZeW"
      },
      "source": [
        "def generate_meta_features(classifiers, X_train, X_test, y_train, cv):\n",
        "    \"\"\"\n",
        "    Generates metafeatures using a list of classifiers.\n",
        "    \n",
        "    :arg classifiers: list of scikit-learn classifiers\n",
        "    :args X_train, y_train: training set\n",
        "    :arg X_test: testing set\n",
        "    :arg cv: cross-validation folding\n",
        "    \"\"\"\n",
        "    features = [\n",
        "        compute_meta_feature(clf, X_train, X_test, y_train, cv)\n",
        "        for clf in tqdm(classifiers)\n",
        "    ]\n",
        "    \n",
        "    stacked_features_train = np.vstack([\n",
        "        features_train for features_train, features_test in features\n",
        "    ]).T\n",
        "\n",
        "    stacked_features_test = np.vstack([\n",
        "        features_test for features_train, features_test in features\n",
        "    ]).T\n",
        "    \n",
        "    return stacked_features_train, stacked_features_test"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V6xy7_0HZeY"
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbv7YXs8HZea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "527dda48-e2dc-4c91-b39a-847679cdc225"
      },
      "source": [
        "clf = GradientBoostingClassifier(n_estimators=300)\n",
        "clf.fit(cover_X_train, cover_y_train)\n",
        "\n",
        "accuracy_score(clf.predict(cover_X_test), cover_y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7822410147991543"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmrhIV1aHZec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7332836-fb42-45ea-ebbe-759c6bc3632c"
      },
      "source": [
        "cv = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\n",
        "    LogisticRegression(C=0.001, penalty='l1', solver='liblinear', max_iter=5000),\n",
        "    LogisticRegression(C=0.001, penalty='l2', solver='liblinear', max_iter=5000),  \n",
        "    RandomForestClassifier(n_estimators=300, n_jobs=-1),\n",
        "    GradientBoostingClassifier(n_estimators=300)\n",
        "], cover_X_train, cover_X_test, cover_y_train.values, cv)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:24<00:00,  6.21s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAqWN10ZHZee"
      },
      "source": [
        "total_features_train = np.hstack([cover_X_train, stacked_features_train])\n",
        "total_features_test = np.hstack([cover_X_test, stacked_features_test])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-wCuCCdHZef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c15c2b-db12-4e8a-dbd6-36c8bc094a27"
      },
      "source": [
        "np.random.seed(42)\n",
        "clf = LogisticRegression(penalty='none', solver='lbfgs')\n",
        "clf.fit(stacked_features_train, cover_y_train)\n",
        "accuracy_score(clf.predict(stacked_features_test), cover_y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7998590556730092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u4HIEbcLS3j"
      },
      "source": [
        "Все задания выполняются на основе датасета:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBPz3vKsLVf3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
        "                              RandomForestClassifier, ExtraTreesClassifier)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import clone\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats.distributions import randint"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJEwa_7KLbZQ"
      },
      "source": [
        "dataset = load_digits()\n",
        "X, y = dataset['data'], dataset['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-xle4-6Lf11"
      },
      "source": [
        "В скринкасте мы разобрали схему генерации признаков в стекинге, когда для тестовой выборки алгоритм заново переобучался на всей тренировочной выборке. Реализуйте схему, когда вместо этого производится агрегация ответов всех обученных на фолдах классификаторов на тестовой выборке при помощи усреднения.\n",
        "\n",
        "Логика решения:\n",
        "\n",
        "*1) Создадим X_meta_test, заполним его нулями (по аналогии с X_meta_train);\n",
        "\n",
        "2) Далее на каждом шаге, где мы обучаем folded_clf.fit (X_fold_train, y_fold_train) и его предсказания на X_fold_predict запихиваем в X_meta_train[predict_fold_index] добавим еще одну строку, где в X_meta_test будем добавлять предсказания вероятностей folded_clf на X_test. Их можно сразу складывать друг с другом или сохранить много массивов, тогда в конце их нужно будет все сложить, а потом делить на количество сплитов (количество массивов равно количеству сплитов в кросс - валидации);\n",
        "\n",
        "3) После цикла останется только усреднить все эти массивы, это и будет наш X_meta_test.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPvm6YAspteQ"
      },
      "source": [
        "def compute_meta_feature_mean(clf, X_train, X_test, y_train, cv):\n",
        "    \"\"\"\n",
        "    Эта функция подсчитывает признаки для мета-классификатора. \n",
        "    Они являются вероятностями классов при решении задачи многоклассовой классификации.\n",
        "    :arg clf: классификатор\n",
        "    :args X_train, y_train: обучающая выборка\n",
        "    :arg X_test: признаки тестовой выборки\n",
        "    :arg cv: класс, генерирующий фолды (KFold)\n",
        "    :returns X_meta_train, X_meta_test: новые признаки для обучающей и тестовой выборок\n",
        "    \"\"\"\n",
        "    n_classes = len(np.unique(y_train)) # сколько уник. элементов класса\n",
        "    # Создадим матрицу из нулей размером количества уник элементов класса.\n",
        "    X_meta_train = np.zeros((len(X_train), n_classes), dtype=np.float32) \n",
        "    X_meta_tests_array = [] # Сюда будем закидывать массивы результатов предсказаний \n",
        "    splits = 0\n",
        "    \"\"\"cv - разбиваем на 10 частей и по очериди их меняем местами в train и test\"\"\"\n",
        "    for train_fold_index, predict_fold_index in cv.split(X_train):\n",
        "        \"\"\" создаем пустой массив для результата предсказаний\"\"\"\n",
        "        n_classes = len(np.unique(y_test)) \n",
        "        X_meta_test = np.zeros((len(X_test), n_classes), dtype=np.float32)\n",
        "        splits += 1 \n",
        "        \"\"\"разбиение происходит по индексам\"\"\"\n",
        "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
        "        y_fold_train = y_train[train_fold_index]\n",
        "        folded_clf = clone(clf)\n",
        "        folded_clf.fit(X_fold_train, y_fold_train)\n",
        "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\n",
        "        X_meta_tests_array.append(folded_clf.predict_proba(X_test))\n",
        "    meta_clf = clone(clf)\n",
        "    meta_clf.fit(X_train, y_train)\n",
        "    X_meta_test = sum(X_meta_tests_array) / splits\n",
        "    return X_meta_train, X_meta_test"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdrhkiHj2PVW"
      },
      "source": [
        "Для следующих заданий используйте этот код:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B64rxE82Ia2"
      },
      "source": [
        "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n",
        "    \n",
        "    n_classes = len(np.unique(y_train))\n",
        "    X_meta_train = np.zeros((len(y_train), n_classes), dtype=np.float32)\n",
        "\n",
        "    splits = cv.split(X_train)\n",
        "    for train_fold_index, predict_fold_index in splits:\n",
        "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
        "        y_fold_train = y_train[train_fold_index]\n",
        "        \n",
        "        folded_clf = clone(clf)\n",
        "        folded_clf.fit(X_fold_train, y_fold_train)\n",
        "        \n",
        "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\n",
        "    \n",
        "    meta_clf = clone(clf)\n",
        "    meta_clf.fit(X_train, y_train)\n",
        "    \n",
        "    X_meta_test = meta_clf.predict_proba(X_test)\n",
        "    \n",
        "    return X_meta_train, X_meta_test"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzz7ShyI2LBg"
      },
      "source": [
        "def generate_meta_features(classifiers, X_train, X_test, y_train, cv):\n",
        "   \n",
        "    features = [\n",
        "        compute_meta_feature(clf, X_train, X_test, y_train, cv)\n",
        "        for clf in tqdm(classifiers)\n",
        "    ]\n",
        "    \n",
        "    stacked_features_train = np.hstack([\n",
        "        features_train for features_train, features_test in features\n",
        "    ])\n",
        "\n",
        "    stacked_features_test = np.hstack([\n",
        "        features_test for features_train, features_test in features\n",
        "    ])\n",
        "    \n",
        "    return stacked_features_train, stacked_features_test"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKDBCpqP2S3U"
      },
      "source": [
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "def compute_metric(clf, X_train=X_train, y_train=y_train, X_test=X_test):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "    return np.round(f1_score(y_test, y_test_pred, average='macro'), 6)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNz6bbEk2xpB"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\n",
        "\n",
        "* логистическая регрессия с L1-регуляризацией, C=0.001, солвер — 'saga', схема работы мультиклассовой классификации — one-vs-rest, максимальное допустимое количество итераций — 2000\n",
        "* логистическая регрессия с L2-регуляризацией, C=0.001, солвер — 'saga', схема работы мультиклассовой классификации — multinomial, максимальное допустимое количество итераций — 2000\n",
        "* случайный лес из 300 деревьев\n",
        "* градиентный бустинг из 200 деревьев"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMqoTfUJ3nzN"
      },
      "source": [
        "Как мета-алгоритм используйте логистическую регрессию без регуляризации со схемой работы мультиклассовой классификации — auto и солвером 'lbfgs'.\n",
        "Посчитайте качество при помощи передачи новых признаков в функцию compute_metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98kTmYl52yVp"
      },
      "source": [
        "lg_reg1 = LogisticRegression(penalty='l1', C=0.001, solver='saga', multi_class='ovr', max_iter=2000, n_jobs=-1, random_state=42)\n",
        "lg_reg2 = LogisticRegression(penalty='l2', C=0.001, solver='saga', multi_class='multinomial', max_iter=2000, n_jobs=-1, random_state=42)\n",
        "r_f = RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)\n",
        "gr_b = GradientBoostingClassifier(n_estimators=200, random_state=42)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8-OaHVciGzx",
        "outputId": "c6799e88-517b-447f-882b-77bdf1833bcb"
      },
      "source": [
        "stacked_features_train, stacked_features_test = generate_meta_features([\n",
        "                                            lg_reg1, \n",
        "                                            lg_reg2, \n",
        "                                            r_f, \n",
        "                                            gr_b\n",
        "                                            ], \n",
        "                                           X_train, X_test, y_train, cv)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 1/4 [00:36<01:49, 36.41s/it]\u001b[A\n",
            " 50%|█████     | 2/4 [00:38<00:52, 26.16s/it]\u001b[A\n",
            " 75%|███████▌  | 3/4 [00:50<00:21, 21.72s/it]\u001b[A\n",
            "100%|██████████| 4/4 [02:20<00:00, 35.17s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdpEuNWKn9PU"
      },
      "source": [
        "Как мета-алгоритм используйте логистическую регрессию без регуляризации со схемой работы мультиклассовой классификации — auto и солвером 'lbfgs'.\n",
        "Посчитайте качество при помощи передачи новых признаков в функцию compute_metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkbSHfqWknVg",
        "outputId": "694fec3b-af6f-4a09-9195-b8d3c8e95bd1"
      },
      "source": [
        "meta_lr = LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42)\n",
        "meta_lr.fit(stacked_features_train, y_train)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57KXTodsmgKJ",
        "outputId": "d6eadcda-28f0-4200-cd0b-28955623e500"
      },
      "source": [
        "compute_metric(meta_lr, stacked_features_train, y_train, stacked_features_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.980848"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x3e2FXjoDmW"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\n",
        "* случайный лес из 300 деревьев\n",
        "* случайный лес из 200 экстремальных деревьев\n",
        "\n",
        "Как мета-алгоритм используйте логистическую регрессию без регуляризации со схемой работы мультиклассовой классификации — auto и солвером 'lbfgs'.\n",
        "\n",
        "Посчитайте качество при помощи передачи новых признаков в функцию compute_metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LUSWD1CoETO",
        "outputId": "588d9352-74fd-4138-8f54-221d83c588ff"
      },
      "source": [
        "r_f1 = RandomForestClassifier(n_estimators=300, n_jobs=-1, random_state=42)\n",
        "r_f2 = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([ \n",
        "                                            r_f1,                            \n",
        "                                            r_f2,                                             \n",
        "                                            ], \n",
        "                                           X_train, X_test, y_train, cv)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:11<00:11, 11.46s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:20<00:00, 10.01s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEG3Hm4Mo4ZR",
        "outputId": "98c554c3-298c-4850-ce5d-a6eec5060345"
      },
      "source": [
        "meta_lr = LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42)\n",
        "meta_lr.fit(stacked_features_train, y_train)\n",
        "compute_metric(meta_lr, stacked_features_train, y_train, stacked_features_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.978682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjeJmw-rpMaf"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\n",
        "\n",
        "* метод ближайшего соседа (k-NN) со стандартными параметрами\n",
        "* случайный лес из 300 экстремальных деревьев\n",
        "\n",
        "Как мета-алгоритм используйте логистическую регрессию без регуляризации со схемой работы мультиклассовой классификации — auto и солвером 'lbfgs'.\n",
        "\n",
        "Посчитайте качество при помощи передачи новых признаков в функцию compute_metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVBowtQXpUY0",
        "outputId": "2879bc1c-c724-4154-c9c5-7b14aca3b435"
      },
      "source": [
        "knn = KNeighborsClassifier(n_jobs=-1)\n",
        "r_f_e = ExtraTreesClassifier(n_estimators=300, n_jobs=-1, random_state=42)\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([ \n",
        "                                            knn,                            \n",
        "                                            r_f_e,                                             \n",
        "                                            ], \n",
        "                                           X_train, X_test, y_train, cv)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 1/2 [00:01<00:01,  1.21s/it]\u001b[A\n",
            "100%|██████████| 2/2 [00:10<00:00,  5.12s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PCKYgb6tXfC",
        "outputId": "2a0c78e8-8339-4b87-c6a7-c4ce286c6ca8"
      },
      "source": [
        "meta_lr = LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42)\n",
        "meta_lr.fit(stacked_features_train, y_train)\n",
        "compute_metric(meta_lr, stacked_features_train, y_train, stacked_features_test)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.987798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt7y7pgit5BV"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\n",
        "\n",
        "* логистическая регрессия с L1-регуляризацией, C=0.001, солвер — 'saga', схема работы мультиклассовой классификации — one-vs-rest, максимальное допустимоей количество итераций — 2000\n",
        "* метод ближайшего соседа со стандартными параметрами\n",
        "* случайный лес из 300 экстремальных деревьев\n",
        "* AdaBoost со стандартными параметрами\n",
        "\n",
        "Как мета-алгоритм используйте логистическую регрессию без регуляризации со схемой работы мультиклассовой классификации — auto и солвером 'lbfgs'.\n",
        "\n",
        "Посчитайте качество при помощи передачи новых признаков в функцию compute_metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj24ls01uFg1",
        "outputId": "da765b4c-d627-4c2a-f49d-c3fbf585c3e8"
      },
      "source": [
        "lg_reg = LogisticRegression(penalty='l1', C=0.001, solver='saga', multi_class='ovr', max_iter=2000, n_jobs=-1, random_state=42)\n",
        "knn = KNeighborsClassifier(n_jobs=-1)\n",
        "r_f_e = ExtraTreesClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "ada = AdaBoostClassifier(random_state=42)\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([                                                                         \n",
        "                                            lg_reg,\n",
        "                                            knn,\n",
        "                                            r_f_e,\n",
        "                                            ada\n",
        "                                            ], \n",
        "                                           X_train, X_test, y_train, cv)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 1/4 [00:36<01:49, 36.42s/it]\u001b[A\n",
            " 50%|█████     | 2/4 [00:37<00:51, 25.86s/it]\u001b[A\n",
            " 75%|███████▌  | 3/4 [00:46<00:20, 20.81s/it]\u001b[A\n",
            "100%|██████████| 4/4 [00:49<00:00, 12.26s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuvZ38p-82eu",
        "outputId": "7957fa41-4fdd-49ec-b545-c2bf1b7ec0be"
      },
      "source": [
        "meta_lr = LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42)\n",
        "meta_lr.fit(stacked_features_train, y_train)\n",
        "compute_metric(meta_lr, stacked_features_train, y_train, stacked_features_test)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.987798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpHelJUu9GR7"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\n",
        "* случайный лес из 300 деревьев\n",
        "* случайный лес из 300 экстремальных деревьев\n",
        "\n",
        "Для генерации фолдов используйте класс StratifiedKFold, который позволяет делать так называемые стратифицированные разбиения (в каждом фолде будет одинаковое соотношение классов).\n",
        "\n",
        "Для корректной работы необходимо подправить код в функции compute_meta_feature. Как мета-алгоритм используйте логистическую регрессию без регуляризации со схемой работы мультиклассовой классификации — auto и солвером 'lbfgs'.\n",
        "\n",
        "Посчитайте качество при помощи передачи новых признаков в функцию compute_metric. Количество фолдов = 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myzwAqbD_uHK"
      },
      "source": [
        "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n",
        "    \n",
        "    n_classes = len(np.unique(y_train))\n",
        "    X_meta_train = np.zeros((len(y_train), n_classes), dtype=np.float32)\n",
        "\n",
        "    splits = cv.split(X_train, y_train)\n",
        "    for train_fold_index, predict_fold_index in splits:\n",
        "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
        "        y_fold_train = y_train[train_fold_index]\n",
        "        \n",
        "        folded_clf = clone(clf)\n",
        "        folded_clf.fit(X_fold_train, y_fold_train)\n",
        "        \n",
        "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\n",
        "    \n",
        "    meta_clf = clone(clf)\n",
        "    meta_clf.fit(X_train, y_train)\n",
        "    \n",
        "    X_meta_test = meta_clf.predict_proba(X_test)\n",
        "    \n",
        "    return X_meta_train, X_meta_test"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRkRxQ879RHn",
        "outputId": "405e56a1-be06-4010-875f-8a0f25d7ed75"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r_f = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "r_f_e = ExtraTreesClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\n",
        "                                            r_f,\n",
        "                                            r_f_e\n",
        "                                            ], \n",
        "                                           X_train, X_test, y_train, cv)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 1/2 [00:06<00:06,  6.34s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 2/2 [00:11<00:00,  5.54s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av3wF0vU_8hK",
        "outputId": "852bb8e6-8188-4567-8500-3c5d0e043495"
      },
      "source": [
        "meta_lr = GradientBoostingClassifier(random_state=42)\n",
        "meta_lr.fit(stacked_features_train, y_train)\n",
        "compute_metric(meta_lr, stacked_features_train, y_train, stacked_features_test)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.987407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ghFYYCJBWFp"
      },
      "source": [
        "Используйте функцию generate_meta_features для стекинга следующих алгоритмов:\n",
        "* случайный лес из 300 деревьев, критерий Джини, максимальная глубина — 24\n",
        "* случайный лес из 300 экстремальных деревьев\n",
        "\n",
        "Для генерации фолдов используйте класс StratifiedKFold, который позволяет делать так называемые стратифицированные разбиения (в каждом фолде будет одинаковое соотношение классов).\n",
        "\n",
        "Для генерации фолдов используйте класс StratifiedKFold и поправленный Вами ранее код в функции compute_meta_feature.\n",
        "Выполните разбиение на 3 фолда.\n",
        "\n",
        "Как мета-алгортм используйте случайный лес из 100 экстремальных деревьев. Посчитайте качество при помощи передачи новых признаков в функцию compute_metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBQk_KHhBVXk",
        "outputId": "0cbd7da3-09d6-4652-fd3c-b7a4e9400c34"
      },
      "source": [
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "r_f = RandomForestClassifier(n_estimators=300, criterion='gini', max_depth=24, random_state=42, n_jobs=-1)\n",
        "r_f_e = ExtraTreesClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "stacked_features_train, stacked_features_test = generate_meta_features([\n",
        "                                            r_f,\n",
        "                                            r_f_e\n",
        "                                            ], \n",
        "                                           X_train, X_test, y_train, cv)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 50%|█████     | 1/2 [00:03<00:03,  3.91s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 2/2 [00:06<00:00,  3.46s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWkyr-FRCDdZ",
        "outputId": "76f60942-be60-4298-b834-a9fe7c9c785b"
      },
      "source": [
        "meta_lr = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "meta_lr.fit(stacked_features_train, y_train)\n",
        "compute_metric(meta_lr, stacked_features_train, y_train, stacked_features_test)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.983967"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhbIJcpJCSqp"
      },
      "source": [
        "Обучите на тренировочной выборке следующие алгоритмы:\n",
        "* случайный лес из 300 деревьев, критерий Джини, максимальная глубина — 24\n",
        "* случайный лес из 300 экстремальных деревьев\n",
        "* логистическую регрессию со стандартными параметрами\n",
        "\n",
        "Усредните их ответы на тестовой выборке методом сложения предсказаний и затем взятия функции argmax: answer = (prediction1 + prediction2 + prediction3).argmax(axis = 1).\n",
        "\n",
        "Посчитайте качество, аналогично функции compute_metric (F1-score с макро-усреднением, округленный до 6 знака)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJguOy1dCbdb",
        "outputId": "b01e5016-5918-4caf-dff8-fc20437fb553"
      },
      "source": [
        "r_f = RandomForestClassifier(n_estimators=300, criterion='gini', random_state=42, n_jobs=-1)\n",
        "r_f_e = ExtraTreesClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "lg_reg = LogisticRegression()\n",
        "\n",
        "def comptue_pipline(classifiers, X_train, X_test, y_train):\n",
        "  predict_array = []\n",
        "  for clf in tqdm(classifiers):\n",
        "    clf.fit(X_train, y_train)\n",
        "    array = clf.predict_proba(X_test)\n",
        "    predict_array.append(array)\n",
        "  return predict_array\n",
        "predict_array = comptue_pipline([r_f, r_f_e, lg_reg], X_train, X_test, y_train)\n",
        "\n",
        "y_test_pred = np.sum(predict_array, axis=0).argmax(axis=1)\n",
        "np.round(f1_score(y_test, y_test_pred, average='macro'), 6)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 33%|███▎      | 1/3 [00:01<00:02,  1.13s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            " 67%|██████▋   | 2/3 [00:01<00:01,  1.04s/it]\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.976259"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    }
  ]
}